/*
 * System detection and adaptive resource allocation
 */

// System capability detection functions
def get_available_cpus() {
    try {
        def runtime = Runtime.getRuntime()
        return runtime.availableProcessors()
    } catch (Exception e) {
        return 4  // Fallback
    }
}

def get_available_memory() {
    try {
        def runtime = Runtime.getRuntime()
        def max_memory = runtime.maxMemory()
        return (max_memory / (1024 * 1024 * 1024)) as nextflow.util.MemoryUnit
    } catch (Exception e) {
        return 16.GB  // Fallback
    }
}

def detect_gpu_count() {
    try {
        def proc = "nvidia-smi --list-gpus".execute()
        proc.waitFor()
        if (proc.exitValue() == 0) {
            def output = proc.text
            return output.split('\n').findAll { it.trim() }.size()
        }
    } catch (Exception e) {
        // GPU detection failed
    }
    return 0
}

def get_gpu_memory_per_device() {
    try {
        def proc = "nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits".execute()
        proc.waitFor()
        if (proc.exitValue() == 0) {
            def output = proc.text.trim()
            def memories = output.split('\n').collect { it.trim() as Integer }
            return memories.min() * 1024 * 1024  // Convert MB to bytes
        }
    } catch (Exception e) {
        // GPU memory detection failed
    }
    return 0
}

def get_scale_factor() {
    // Scale resources based on dataset size hints
    def input_size = params.input_size ?: 'medium'
    switch (input_size) {
        case 'small':  return 0.5
        case 'medium': return 1.0
        case 'large':  return 1.5
        case 'xlarge': return 2.0
        default:       return 1.0
    }
}

def get_memory_scale_factor(process_type) {
    def base_factor = get_scale_factor()

    // Process-specific memory scaling
    def process_factors = [
        'validation': 0.5,
        'preprocess': 1.0,
        'single': 0.5,
        'low': 0.8,
        'medium': 1.0,
        'high': 1.5,
        'high_memory': 2.0,
        'gpu': 1.5,
        'analyze': 1.0,
        'visualize': 0.8
    ]

    def process_factor = process_factors[process_type] ?: 1.0
    return base_factor * process_factor
}

def get_system_type() {
    def available_memory = get_available_memory().toGiga()
    def available_cpus = get_available_cpus()
    def gpu_count = detect_gpu_count()

    if (gpu_count >= 4 && available_memory >= 256 && available_cpus >= 32) {
        return 'hpc_gpu'
    } else if (gpu_count >= 1 && available_memory >= 64 && available_cpus >= 16) {
        return 'workstation_gpu'
    } else if (available_memory >= 32 && available_cpus >= 8) {
        return 'workstation'
    } else {
        return 'laptop'
    }
}

