/*
 * -------------------------------------------------
 *  nf-core/resolvinf Nextflow base config file
 * -------------------------------------------------
 * A 'blank slate' config file, appropriate for general
 * use on most high performance compute environments.
 * Assumes that all software is installed and available
 * on the PATH. Runs in `local` mode - all jobs will be
 * run on the logged in environment.
 */

process {

    cpus   = { check_max( 1    * task.attempt, 'cpus'   ) }
    memory = { check_max( 6.GB * task.attempt, 'memory' ) }
    time   = { check_max( 4.h  * task.attempt, 'time'   ) }

    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries    = 1
    maxErrors     = '-1'

    // Process-specific resource requirements
    // NOTE - Please try and re-use the labels below as much as possible.
    //        These labels are used and recognised by default in DSL2 files hosted on nf-core/modules.
    //        If possible, it would be nice to keep the same label naming convention when
    //        adding in your local modules too.
    // See https://www.nextflow.io/docs/latest/config.html#config-process-selectors
    withLabel:process_single {
        cpus   = { check_max( 1                  , 'cpus'    ) }
        memory = { check_max( 6.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 4.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_low {
        cpus   = { check_max( 2     * task.attempt, 'cpus'    ) }
        memory = { check_max( 12.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 4.h   * task.attempt, 'time'    ) }
    }
    withLabel:process_medium {
        cpus   = { check_max( 6     * task.attempt, 'cpus'    ) }
        memory = { check_max( 36.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 8.h   * task.attempt, 'time'    ) }
    }
    withLabel:process_high {
        cpus   = { check_max( 12    * task.attempt, 'cpus'    ) }
        memory = { check_max( 72.GB * task.attempt, 'memory'  ) }
        time   = { check_max( 16.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_long {
        time   = { check_max( 20.h  * task.attempt, 'time'    ) }
    }
    withLabel:process_high_memory {
        memory = { check_max( 200.GB * task.attempt, 'memory' ) }
    }
    withLabel:error_ignore {
        errorStrategy = 'ignore'
    }
    withLabel:error_retry {
        errorStrategy = 'retry'
        maxRetries    = 2
    }

    // Dynamic GPU allocation based on availability

    withLabel: process_gpu {
        accelerator = { 
            def gpu_count = params.force_cpu ? 0 : Math.min(params.num_gpus ?: 0, params.max_gpus_per_process ?: 1)
            gpu_count > 0 ? [request: gpu_count, type: 'nvidia'] : null
        }
    
        memory = { 
            def base_mem = params.force_cpu ? '32.GB' : '64.GB'
            def gpu_mem = task.accelerator ? "${task.accelerator.request * 16}.GB" : '0.GB'
            check_max("${base_mem}".toMemoryUnit() + "${gpu_mem}".toMemoryUnit(), 'memory')
        }
    
        containerOptions = {
            def options = ''
            if (task.accelerator && workflow.containerEngine == 'singularity') {
                options += ' --nv'
            } else if (task.accelerator && workflow.containerEngine == 'docker') {
                options += ' --gpus all'
            }
            return options
        }
    }

/    // Process-specific configurations based on LSF script
/    withName:RESOLVI_PREPROCESS {
/        cpus   = { check_max( 4     * task.attempt, 'cpus'    ) }
/        memory = { check_max( 32.GB * task.attempt, 'memory'  ) }
/        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
/
/        // Add LSF project specification for preprocess
/        queue = 'gpu'
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=8G]\""
/            options += " -R h100nvl"
/            options += " -gpu num=1"
/            return options
/        }
/    }
/
/    // Based on LSF script: 16 CPUs, 16GB per CPU (256GB total), 12h, 4 GPUs
/    withName:RESOLVI_TRAIN {
/        cpus   = { check_max( 16    * task.attempt, 'cpus'    ) }
/        memory = { check_max( 256.GB * task.attempt, 'memory' ) }
/        time   = { check_max( 12.h  * task.attempt, 'time'    ) }
/
/        // GPU configuration based on LSF script
/        queue = 'gpu'
/
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=16G]\""
/            options += " -R h100nvl"
/
/            // GPU configuration matching your successful LSF script
/            if (params.num_gpus == null || params.num_gpus == 4) {
/                options += " -gpu num=4"
/            } else if (params.num_gpus == -1) {
/                options += " -gpu num=4"  // Default to 4 for "all available"
/            } else if (params.num_gpus == 0) {
/                // CPU only - change queue and remove GPU options
/                queue = 'premium'
/                return options  // Return without GPU options
/            } else {
/                options += " -gpu num=${params.num_gpus}"
/            }
/
/            return options
/        }
/    }
/
/    // ANALYZE - CPU only, no GPU needed
/    withName:RESOLVI_ANALYZE {
/        cpus   = { check_max( 8     * task.attempt, 'cpus'    ) }
/        memory = { check_max( 64.GB * task.attempt, 'memory'  ) }
/        time   = { check_max( 8.h   * task.attempt, 'time'    ) }
/
/        // Use CPU queue and add required project specification
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=8G]\""
/            return options
/        }
/    }
/
/    // VISUALIZE - CPU only, no GPU needed
/    withName:RESOLVI_VISUALIZE {
/        cpus   = { check_max( 4     * task.attempt, 'cpus'    ) }
/        memory = { check_max( 32.GB * task.attempt, 'memory'  ) }
/        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
/
/        // Use CPU queue and add required project specification
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=8G]\""
/            return options
/        }
/    }
/
/    // scVIVA training with same GPU config as RESOLVI_TRAIN
/    withName:SCVIVA_TRAIN {
/        cpus   = { check_max( 16    * task.attempt, 'cpus'    ) }
/        memory = { check_max( 256.GB * task.attempt, 'memory' ) }
/        time   = { check_max( 12.h  * task.attempt, 'time'    ) }
/
/        // GPU configuration matching RESOLVI_TRAIN exactly
/        queue = 'gpu'
/
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=16G]\""
/            options += " -R h100nvl"
/
/            // GPU configuration matching RESOLVI_TRAIN
/            if (params.num_gpus == null || params.num_gpus == 4) {
/                options += " -gpu num=4"
/            } else if (params.num_gpus == -1) {
/                options += " -gpu num=4"  // Default to 4 for "all available"
/            } else if (params.num_gpus == 0) {
/                // CPU only - change queue and remove GPU options
/                queue = 'premium'
/                return options  // Return without GPU options
/            } else {
/                options += " -gpu num=${params.num_gpus}"
/            }
/
/            return options
/        }
/    }
/
/
/    withName:SCVIVA_ANALYZE {
/        cpus   = { check_max( 8     * task.attempt, 'cpus'    ) }
/        memory = { check_max( 64.GB * task.attempt, 'memory'  ) }
/        time   = { check_max( 6.h   * task.attempt, 'time'    ) }
/        clusterOptions = {
/            def options = "-P ${System.getenv('MINERVA_ALLOCATION') ?: params.minerva_allocation}"
/            options += " -R \"rusage[mem=8G]\""
/            return options
/        }
/    }

    withName:get_software_versions {
        cache = false
    }
}
